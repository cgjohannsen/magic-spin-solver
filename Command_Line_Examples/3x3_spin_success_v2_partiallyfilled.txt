[chrisj17@linuxremote1 Magic_Squares]$ ./pan
warning: never claim + accept labels requires -a flag to fully verify
warning: for p.o. reduction to be valid the never claim must be stutter-invariant
(never claims generated from LTL formulae are stutter-invariant)
Depth=      83 States=    1e+06 Transitions= 1.22e+06 Memory=   208.515 t=     1.34 R=   7e+05
Depth=      83 States=    2e+06 Transitions= 2.46e+06 Memory=   288.593 t=     2.22 R=   9e+05
Depth=      83 States=    3e+06 Transitions= 3.71e+06 Memory=   368.769 t=     3.12 R=   1e+06
Depth=      83 States=    4e+06 Transitions= 4.97e+06 Memory=   448.944 t=     4.04 R=   1e+06
Depth=      83 States=    5e+06 Transitions= 6.23e+06 Memory=   529.218 t=     4.98 R=   1e+06
Depth=      83 States=    6e+06 Transitions= 7.49e+06 Memory=   609.394 t=     5.93 R=   1e+06
Depth=      83 States=    7e+06 Transitions= 8.74e+06 Memory=   689.569 t=      6.9 R=   1e+06
Depth=      83 States=    8e+06 Transitions=    1e+07 Memory=   769.745 t=     7.87 R=   1e+06
Depth=      83 States=    9e+06 Transitions= 1.13e+07 Memory=   850.214 t=     8.88 R=   1e+06
Depth=      83 States=    1e+07 Transitions= 1.26e+07 Memory=   930.683 t=     9.87 R=   1e+06
Depth=      83 States=  1.1e+07 Transitions= 1.38e+07 Memory=  1011.054 t=     10.9 R=   1e+06
Depth=      83 States=  1.2e+07 Transitions= 1.51e+07 Memory=  1091.425 t=     11.9 R=   1e+06
Depth=      83 States=  1.3e+07 Transitions= 1.64e+07 Memory=  1171.991 t=     12.9 R=   1e+06
Depth=      83 States=  1.4e+07 Transitions= 1.77e+07 Memory=  1252.558 t=       14 R=   1e+06
Depth=      83 States=  1.5e+07 Transitions=  1.9e+07 Memory=  1332.831 t=       15 R=   1e+06
Depth=      83 States=  1.6e+07 Transitions= 2.03e+07 Memory=  1413.495 t=     16.1 R=   1e+06
Depth=      83 States=  1.7e+07 Transitions= 2.16e+07 Memory=  1494.062 t=     17.2 R=   1e+06
Depth=      83 States=  1.8e+07 Transitions= 2.28e+07 Memory=  1574.335 t=     18.3 R=   1e+06
Depth=      83 States=  1.9e+07 Transitions= 2.41e+07 Memory=  1654.999 t=     19.4 R=   1e+06
Depth=      83 States=    2e+07 Transitions= 2.54e+07 Memory=  1735.468 t=     20.5 R=   1e+06
Depth=      83 States=  2.1e+07 Transitions= 2.67e+07 Memory=  1815.839 t=     21.6 R=   1e+06
Depth=      83 States=  2.2e+07 Transitions=  2.8e+07 Memory=  1896.405 t=     22.7 R=   1e+06
Depth=      83 States=  2.3e+07 Transitions= 2.93e+07 Memory=  1976.776 t=     23.8 R=   1e+06
Depth=      83 States=  2.4e+07 Transitions= 3.06e+07 Memory=  2057.245 t=       25 R=   1e+06
Depth=      83 States=  2.5e+07 Transitions= 3.19e+07 Memory=  2137.812 t=     26.1 R=   1e+06
Depth=      83 States=  2.6e+07 Transitions= 3.31e+07 Memory=  2218.085 t=     27.2 R=   1e+06
Depth=      83 States=  2.7e+07 Transitions= 3.44e+07 Memory=  2298.651 t=     28.4 R=   9e+05
Depth=      83 States=  2.8e+07 Transitions= 3.57e+07 Memory=  2379.022 t=     29.6 R=   9e+05
Depth=      83 States=  2.9e+07 Transitions=  3.7e+07 Memory=  2459.491 t=     30.8 R=   9e+05
Depth=      83 States=    3e+07 Transitions= 3.83e+07 Memory=  2540.058 t=       32 R=   9e+05
Depth=      83 States=  3.1e+07 Transitions= 3.96e+07 Memory=  2620.331 t=     33.1 R=   9e+05
Depth=      83 States=  3.2e+07 Transitions= 4.08e+07 Memory=  2700.897 t=     34.4 R=   9e+05
Depth=      83 States=  3.3e+07 Transitions= 4.21e+07 Memory=  2781.366 t=     35.5 R=   9e+05
Depth=      83 States=  3.4e+07 Transitions= 4.34e+07 Memory=  2861.737 t=     36.8 R=   9e+05
pan: resizing hashtable to -w26..  done
Depth=      83 States=  3.5e+07 Transitions= 4.47e+07 Memory=  3438.386 t=     43.1 R=   8e+05
Depth=      83 States=  3.6e+07 Transitions=  4.6e+07 Memory=  3518.855 t=     44.1 R=   8e+05
Depth=      83 States=  3.7e+07 Transitions= 4.73e+07 Memory=  3599.616 t=     45.1 R=   8e+05
Depth=      83 States=  3.8e+07 Transitions= 4.86e+07 Memory=  3680.378 t=     46.2 R=   8e+05
Depth=      83 States=  3.9e+07 Transitions=    5e+07 Memory=  3761.237 t=     47.2 R=   8e+05
Depth=      83 States=    4e+07 Transitions= 5.13e+07 Memory=  3841.999 t=     48.3 R=   8e+05
Depth=      83 States=  4.1e+07 Transitions= 5.26e+07 Memory=  3922.858 t=     49.4 R=   8e+05
Depth=      83 States=  4.2e+07 Transitions= 5.39e+07 Memory=  4003.620 t=     50.4 R=   8e+05
Depth=      83 States=  4.3e+07 Transitions= 5.52e+07 Memory=  4084.382 t=     51.5 R=   8e+05
Depth=      83 States=  4.4e+07 Transitions= 5.66e+07 Memory=  4165.144 t=     52.6 R=   8e+05
Depth=      83 States=  4.5e+07 Transitions= 5.79e+07 Memory=  4245.905 t=     53.6 R=   8e+05
Depth=      83 States=  4.6e+07 Transitions= 5.92e+07 Memory=  4326.667 t=       55 R=   8e+05
Depth=      83 States=  4.7e+07 Transitions= 6.05e+07 Memory=  4407.526 t=     56.1 R=   8e+05
Depth=      83 States=  4.8e+07 Transitions= 6.18e+07 Memory=  4487.897 t=     57.2 R=   8e+05
Depth=      83 States=  4.9e+07 Transitions= 6.31e+07 Memory=  4568.464 t=     58.2 R=   8e+05
Depth=      83 States=    5e+07 Transitions= 6.44e+07 Memory=  4649.030 t=     59.3 R=   8e+05
Depth=      83 States=  5.1e+07 Transitions= 6.57e+07 Memory=  4729.694 t=     60.4 R=   8e+05
Depth=      83 States=  5.2e+07 Transitions=  6.7e+07 Memory=  4810.554 t=     61.5 R=   8e+05
Depth=      83 States=  5.3e+07 Transitions= 6.84e+07 Memory=  4891.413 t=     62.6 R=   8e+05
Depth=      83 States=  5.4e+07 Transitions= 6.97e+07 Memory=  4972.370 t=     63.8 R=   8e+05
Depth=      83 States=  5.5e+07 Transitions=  7.1e+07 Memory=  5053.327 t=     64.9 R=   8e+05
Depth=      83 States=  5.6e+07 Transitions= 7.24e+07 Memory=  5134.284 t=       66 R=   8e+05
Depth=      83 States=  5.7e+07 Transitions= 7.37e+07 Memory=  5215.144 t=     67.2 R=   8e+05
Depth=      83 States=  5.8e+07 Transitions=  7.5e+07 Memory=  5296.101 t=     68.3 R=   8e+05
Depth=      83 States=  5.9e+07 Transitions= 7.64e+07 Memory=  5376.960 t=     69.4 R=   8e+05
Depth=      83 States=    6e+07 Transitions= 7.77e+07 Memory=  5457.526 t=     70.5 R=   9e+05
Depth=      83 States=  6.1e+07 Transitions=  7.9e+07 Memory=  5537.995 t=     71.6 R=   9e+05
Depth=      83 States=  6.2e+07 Transitions= 8.03e+07 Memory=  5618.562 t=     72.7 R=   9e+05
Depth=      83 States=  6.3e+07 Transitions= 8.16e+07 Memory=  5699.226 t=     73.9 R=   9e+05
Depth=      83 States=  6.4e+07 Transitions= 8.29e+07 Memory=  5779.987 t=       75 R=   9e+05
Depth=      83 States=  6.5e+07 Transitions= 8.42e+07 Memory=  5861.140 t=     76.2 R=   9e+05
Depth=      83 States=  6.6e+07 Transitions= 8.56e+07 Memory=  5942.097 t=     77.3 R=   9e+05
Depth=      83 States=  6.7e+07 Transitions= 8.69e+07 Memory=  6023.054 t=     78.5 R=   9e+05
Depth=      83 States=  6.8e+07 Transitions= 8.82e+07 Memory=  6103.913 t=     79.6 R=   9e+05
Depth=      83 States=  6.9e+07 Transitions= 8.96e+07 Memory=  6184.772 t=     80.8 R=   9e+05
Depth=      83 States=    7e+07 Transitions= 9.09e+07 Memory=  6265.730 t=       82 R=   9e+05
Depth=      83 States=  7.1e+07 Transitions= 9.22e+07 Memory=  6346.003 t=     83.1 R=   9e+05
Depth=      83 States=  7.2e+07 Transitions= 9.35e+07 Memory=  6426.569 t=     84.2 R=   9e+05
Depth=      83 States=  7.3e+07 Transitions= 9.48e+07 Memory=  6507.136 t=     85.3 R=   9e+05
Depth=      83 States=  7.4e+07 Transitions= 9.61e+07 Memory=  6587.995 t=     86.5 R=   9e+05
Depth=      83 States=  7.5e+07 Transitions= 9.74e+07 Memory=  6668.855 t=     87.7 R=   9e+05
Depth=      83 States=  7.6e+07 Transitions= 9.88e+07 Memory=  6749.714 t=     88.9 R=   9e+05
Depth=      83 States=  7.7e+07 Transitions=    1e+08 Memory=  6830.671 t=     90.1 R=   9e+05
Depth=      83 States=  7.8e+07 Transitions= 1.01e+08 Memory=  6911.530 t=     91.2 R=   9e+05
Depth=      83 States=  7.9e+07 Transitions= 1.03e+08 Memory=  6992.487 t=     92.4 R=   9e+05
Depth=      83 States=    8e+07 Transitions= 1.04e+08 Memory=  7073.347 t=     93.6 R=   9e+05
Depth=      83 States=  8.1e+07 Transitions= 1.05e+08 Memory=  7153.718 t=     94.7 R=   9e+05
Depth=      83 States=  8.2e+07 Transitions= 1.07e+08 Memory=  7234.284 t=     95.9 R=   9e+05
pan:1: assertion violated  !((((((((((target_sum==((board[0]+board[1])+board[2]))&&(target_sum==((board[3]+board[4])+board[5])))&&(target_sum==((board[6]+board[7])+board[8])))&&(target_sum==((board[0]+board[3])+board[6])))&&(target_sum==((board[1]+board[4])+board[7])))&&(target_sum==((board[2]+board[5])+board[8])))&&(target_sum==((board[0]+board[4])+board[8])))&&(target_sum==((board[2]+board[4])+board[6])))&&(board[0]==2))) (at depth 74)
pan: wrote pan_in.trail

(Spin Version 6.4.6 -- 2 December 2016)
Warning: Search not completed
        + Partial Order Reduction

Full statespace search for:
        never claim             + (never_0)
        assertion violations    + (if within scope of claim)
        acceptance   cycles     - (not selected)
        invalid end states      - (disabled by never claim)

State-vector 76 byte, depth reached 83, errors: 1
 82467532 states, stored
 24799068 states, matched
1.072666e+08 transitions (= stored+matched)
        0 atomic steps
hash conflicts:  32720782 (resolved)

Stats on memory usage (in Megabytes):
 8179.305       equivalent memory usage for states (stored*(State-vector + overhead))
 6762.014       actual memory usage for states (compression: 82.67%)
                state-vector as stored = 58 byte + 28 byte overhead
  512.000       memory used for hash table (-w26)
    0.534       memory used for DFS stack (-m10000)
    2.666       memory lost to fragmentation
 7271.882       total actual memory usage



pan: elapsed time 96.5 seconds
pan: rate 854851.58 states/second
[chrisj17@linuxremote1 Magic_Squares]$ spin -t pan_in
Never claim moves to line 39    [(1)]
spin: pan_in:38, Error: assertion violated
spin: text of failed assertion: assert(!((((((((((target_sum==((board[0]+board[1])+board[2]))&&(target_sum==((board[3]+board[4])+board[5])))&&(target_sum==((board[6]+board[7])+board[8])))&&(target_sum==((board[0]+board[3])+board[6])))&&(target_sum==((board[1]+board[4])+board[7])))&&(target_sum==((board[2]+board[5])+board[8])))&&(target_sum==((board[0]+board[4])+board[8])))&&(target_sum==((board[2]+board[4])+board[6])))&&(board[0]==2))))
Never claim moves to line 38    [assert(!((((((((((target_sum==((board[0]+board[1])+board[2]))&&(target_sum==((board[3]+board[4])+board[5])))&&(target_sum==((board[6]+board[7])+board[8])))&&(target_sum==((board[0]+board[3])+board[6])))&&(target_sum==((board[1]+board[4])+board[7])))&&(target_sum==((board[2]+board[5])+board[8])))&&(target_sum==((board[0]+board[4])+board[8])))&&(target_sum==((board[2]+board[4])+board[6])))&&(board[0]==2))))]
spin: trail ends after 75 steps
#processes: 2
                target_sum = 15
                board[0] = 2
                board[1] = 7
                board[2] = 6
                board[3] = 9
                board[4] = 5
                board[5] = 1
                board[6] = 4
                board[7] = 3
                board[8] = 8
 75:    proc  1 (fill:1) pan_in:26 (state 15)
 75:    proc  0 (:init::1) pan_in:35 (state 2) <valid end state>
 75:    proc  - (never_0:1) pan_in:37 (state 6)
2 processes created
